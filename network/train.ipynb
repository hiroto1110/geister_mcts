{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from batch import FORMAT_XARC, load\n",
    "from players.base import play_game\n",
    "from players.simple import PlayerTracing\n",
    "from players.strategy import StrategyTokenProducer\n",
    "import  env.state as game\n",
    "\n",
    "def create_pos_history_from_tokens(tokens: np.ndarray, color_o: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    pos_history = np.zeros((tokens.shape[0], 16), dtype=np.uint8)\n",
    "    action_history = np.zeros((tokens.shape[0]), dtype=np.uint8)\n",
    "\n",
    "    if tokens[0, game.Token.Y] < 3:\n",
    "        pos = np.array([1, 2, 3, 4, 7, 8, 9, 10, 25, 26, 27, 28, 31, 32, 33, 34])\n",
    "    else:\n",
    "        pos = np.array([1, 2, 3, 4, 7, 8, 9, 10, 25, 26, 27, 28, 31, 32, 33, 34])\n",
    "\n",
    "        empty_mask = np.any(tokens != 0, axis=1)\n",
    "\n",
    "        id_p_mask = empty_mask * (tokens[:, game.Token.ID] < 8)\n",
    "        id_o_mask = empty_mask * (tokens[:, game.Token.ID] >= 8)\n",
    "\n",
    "        tokens[id_p_mask, game.Token.ID] = 7 - tokens[id_p_mask, game.Token.ID]\n",
    "        tokens[id_o_mask, game.Token.ID] = 7 - (tokens[id_o_mask, game.Token.ID] - 8) + 8\n",
    "\n",
    "        mask = (tokens[:, game.Token.X] != 6) * (tokens[:, game.Token.Y] != 6) * empty_mask\n",
    "\n",
    "        tokens[mask, game.Token.X] = 5 - tokens[mask, game.Token.X]\n",
    "        tokens[mask, game.Token.Y] = 5 - tokens[mask, game.Token.Y]\n",
    "\n",
    "        tokens[:8] = tokens[:8][::-1]\n",
    "\n",
    "    diff_mask = pos[:8] != (tokens[:8, game.Token.X] + tokens[:8, game.Token.Y] * 6)\n",
    "\n",
    "    if np.any(diff_mask):\n",
    "        assert np.sum(diff_mask) == 1, f\"{pos[:8]}, {tokens[:8, game.Token.X] + tokens[:8, game.Token.Y] * 6}\"\n",
    "\n",
    "        diff_id = np.arange(8)[diff_mask][0]\n",
    "\n",
    "        tokens[9:] = tokens[8:-1]\n",
    "        tokens[9:, game.Token.T] += 1\n",
    "\n",
    "        tokens[8] = tokens[diff_id]\n",
    "        tokens[8, game.Token.T] = 1\n",
    "\n",
    "    for i, (c, id, x, y, t) in enumerate(tokens):\n",
    "        if np.all(tokens[i] == 0):\n",
    "            break\n",
    "\n",
    "        if x < 6 and y < 6:\n",
    "            pos[id] = x + 6 * y\n",
    "        else:\n",
    "            pos[id] = 36\n",
    "\n",
    "        pos_history[t] = pos\n",
    "\n",
    "        if t > 0 and x < 6 and y < 6 and (tokens[i - 1, game.Token.T] != tokens[i, game.Token.T]):\n",
    "            d = int(pos_history[t, id]) - int(pos_history[t - 1, id])\n",
    "\n",
    "            if d == -6:\n",
    "                d_i = 0\n",
    "            elif d == -1:\n",
    "                d_i = 1\n",
    "            elif d == 1:\n",
    "                d_i = 2\n",
    "            elif d == 6:\n",
    "                d_i = 3\n",
    "            else:\n",
    "                assert False, f\"{(c, id, x, y, t)}, {pos_history[t, id]}, {pos_history[t - 1, id]}\"\n",
    "\n",
    "            if id < 8:\n",
    "                action_history[t - 1] = id * 4 + d_i\n",
    "            else:\n",
    "                action_history[t - 1] = (15 - id) * 4 + 3 - d_i\n",
    "            \n",
    "            last_t = t\n",
    "\n",
    "    if tokens[8, game.Token.ID] < 8:\n",
    "        return action_history[:last_t], tokens[:8, game.Token.COLOR], color_o[::-1]\n",
    "    else:\n",
    "        return action_history[:last_t], color_o, tokens[:8, game.Token.COLOR]\n",
    "\n",
    "batch = load(\"../data/replay_buffer/run-7.npy\")\n",
    "batch = batch.reshape(-1, batch.shape[-1])\n",
    "print(batch.shape)\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def func(b):\n",
    "    t, _, r, c = FORMAT_XARC.astuple(b)\n",
    "    action_history, color_p, color_o = create_pos_history_from_tokens(t, c)\n",
    "    #  print(action_history, len(action_history))\n",
    "    player = PlayerTracing(action_history)\n",
    "    result = play_game(\n",
    "        player, player,\n",
    "        color1=color_p,\n",
    "        color2=color_o,\n",
    "        token_producer=StrategyTokenProducer(),\n",
    "        print_board=False,\n",
    "        game_length=199\n",
    "    )\n",
    "\n",
    "    return result.create_sample_p(token_length=220)\n",
    "\n",
    "if True:\n",
    "    pool = multiprocessing.Pool(20)\n",
    "    results = pool.map(func, iterable=batch[:])\n",
    "else:\n",
    "    results = []\n",
    "    for i in range(2745, 2746):\n",
    "        print(i)\n",
    "        results.append(func(batch[i]))\n",
    "\n",
    "batch_dst = np.stack(results, axis=0)\n",
    "print(batch_dst.shape)\n",
    "\n",
    "np.save(\"../data/replay_buffer/run-7-st.npy\", batch_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1268736, 1769)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from batch import load\n",
    "\n",
    "batch_org = load(\"../data/replay_buffer/run-7-st.npy\")\n",
    "\n",
    "batch_org = batch_org.reshape(-1, batch_org.shape[-1])\n",
    "\n",
    "indices = np.arange(len(batch_org))\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "batch_org = batch_org[indices]\n",
    "print(batch_org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "import optax\n",
    "from network.transformer import TransformerConfig, TrainStateTransformer\n",
    "from network.train import fit, MinibatchProducerSimple\n",
    "from network.checkpoints import Checkpoint, CheckpointManager\n",
    "from batch import FORMAT_X7ARC\n",
    "\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "batch = batch_org[:500000]\n",
    "\n",
    "n_train = int(batch.shape[0] * 0.8)\n",
    "train_batch = batch[:n_train]\n",
    "test_batch = batch[n_train:]\n",
    "\n",
    "minibatch_producer = MinibatchProducerSimple(batch_size=32)\n",
    "\n",
    "heads = 4,\n",
    "dims = 256,\n",
    "num_layers = 4,\n",
    "\n",
    "for h, d, n in itertools.product(heads, dims, num_layers):\n",
    "    model_config = TransformerConfig(\n",
    "        num_heads=h,\n",
    "        embed_dim=d,\n",
    "        num_hidden_layers=n,\n",
    "    )\n",
    "    model = model_config.create_model()\n",
    "\n",
    "    init_x, _, _, _ = FORMAT_X7ARC.astuple(train_batch[:1])\n",
    "    print(init_x.shape)\n",
    "\n",
    "    variables = model.init(random.PRNGKey(0), init_x)\n",
    "    state = TrainStateTransformer.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=variables['params'],\n",
    "        tx=optax.adam(learning_rate=0.0005),\n",
    "        dropout_rng=random.PRNGKey(0),\n",
    "        epoch=0,\n",
    "    )\n",
    "\n",
    "    ckpt_dir = f'./data/checkpoints/tr-not-st'\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(ckpt_dir)\n",
    "    checkpoint_manager.save(Checkpoint(state.epoch, model_config, state.params))\n",
    "\n",
    "    state = fit(\n",
    "        state, model_config, checkpoint_manager,\n",
    "        train_batches=train_batch,\n",
    "        test_batches=test_batch,\n",
    "        minibatch_producer=minibatch_producer,\n",
    "        epochs=8,\n",
    "        log_wandb=False\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "st\n",
    "Epoch: 1, Loss: (3.734, 3.355), P: (1.546, 1.278), V: (1.635, 1.572), C: (0.553, 0.506)\n",
    "Epoch: 2, Loss: (3.356, 3.263), P: (1.286, 1.217), V: (1.567, 1.553), C: (0.503, 0.493)\n",
    "Epoch: 3, Loss: (3.278, 3.218), P: (1.238, 1.189), V: (1.547, 1.543), C: (0.494, 0.486)\n",
    "Epoch: 4, Loss: (3.237, 3.191), P: (1.213, 1.172), V: (1.535, 1.535), C: (0.490, 0.484)\n",
    "\n",
    "not-st\n",
    "Epoch: 1, Loss: (3.735, 3.386), P: (1.537, 1.288), V: (1.648, 1.594), C: (0.550, 0.504)\n",
    "Epoch: 2, Loss: (3.384, 3.301), P: (1.293, 1.230), V: (1.591, 1.578), C: (0.500, 0.493)\n",
    "Epoch: 3, Loss: (3.316, 3.260), P: (1.248, 1.204), V: (1.575, 1.570), C: (0.493, 0.487)\n",
    "Epoch: 4, Loss: (3.278, 3.240), P: (1.224, 1.189), V: (1.566, 1.565), C: (0.488, 0.486)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geister12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
