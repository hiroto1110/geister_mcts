{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1268736, 1329)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1268736/1268736 [09:53<00:00, 2138.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from batch import load, get_tokens, get_color, get_action, get_reward, get_seq_len\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_pos_history_from_tokens(tokens: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    pos_history = np.zeros((tokens.shape[0], 16), dtype=np.uint8)\n",
    "    action_history = np.zeros((tokens.shape[0]), dtype=np.uint8)\n",
    "\n",
    "    if tokens[0, 3] < 3:\n",
    "        invert = False\n",
    "        pos = np.array([1, 2, 3, 4, 7, 8, 9, 10, 25, 26, 27, 28, 31, 32, 33, 34])\n",
    "    else:\n",
    "        invert = True\n",
    "        pos = 35 - np.array([25, 26, 27, 28, 31, 32, 33, 34, 1, 2, 3, 4, 7, 8, 9, 10])\n",
    "\n",
    "    for i, (c, id, x, y, t) in enumerate(tokens):\n",
    "        if np.all(tokens[i] == 0):\n",
    "            break\n",
    "\n",
    "        if x < 6 and y < 6:\n",
    "            pos[id] = x + 6 * y\n",
    "            if invert:\n",
    "                pos[id] = 35 - pos[id]\n",
    "        else:\n",
    "            pos[id] = 36\n",
    "\n",
    "        pos_history[t] = pos\n",
    "\n",
    "        if t > 1 and x < 6 and y < 6 and (tokens[i - 1, 4] != tokens[i, 4]):\n",
    "            d = int(pos_history[t, id]) - int(pos_history[t - 1, id])\n",
    "\n",
    "            if d == -6:\n",
    "                d_i = 0\n",
    "            elif d == -1:\n",
    "                d_i = 1\n",
    "            elif d == 1:\n",
    "                d_i = 2\n",
    "            elif d == 6:\n",
    "                d_i = 3\n",
    "            else:\n",
    "                assert False, f\"{(c, id, x, y, t)}, {pos_history[t, id]}, {pos_history[t - 1, id]}\"\n",
    "\n",
    "            action_history[t - 1] = pos_history[t - 1, id] * 4 + d_i\n",
    "    \n",
    "    return pos_history, action_history\n",
    "\n",
    "batch = load(\"../data/replay_buffer/run-7.npy\")\n",
    "batch = batch.reshape(-1, batch.shape[-1])\n",
    "print(batch.shape)\n",
    "\n",
    "seq_len = get_seq_len(batch.shape[-1])\n",
    "\n",
    "batch_new = np.zeros((batch.shape[0], batch.shape[1] + 16 * seq_len), dtype=np.uint8)\n",
    "\n",
    "for i, batch_i in tqdm(list(enumerate(batch))):\n",
    "    t = get_tokens(batch_i)\n",
    "    c = get_color(batch_i)\n",
    "    a = get_action(batch_i)\n",
    "    r = get_reward(batch_i)\n",
    "\n",
    "    p, a = create_pos_history_from_tokens(t)\n",
    "\n",
    "    if t[0, 3] > 3:\n",
    "        mask = np.all(t == 0, axis=-1)\n",
    "\n",
    "        t[t[:, 2] != 6, 2] = 5 - t[t[:, 2] != 6, 2]\n",
    "        t[t[:, 3] != 6, 3] = 5 - t[t[:, 3] != 6, 3]\n",
    "\n",
    "        t[mask] = 0\n",
    "\n",
    "        c = c[::-1]\n",
    "\n",
    "    a = a[t[:, 4]]\n",
    "    p = p[t[:, 4]]\n",
    "\n",
    "    p = p.reshape(seq_len * p.shape[-1])\n",
    "    t = t.reshape(seq_len * t.shape[-1])\n",
    "\n",
    "    batch_new[i] = np.concatenate(\n",
    "        [p, t, a, np.array([r]), c],\n",
    "        axis=-1,\n",
    "        dtype=np.uint8\n",
    "    )\n",
    "\n",
    "np.save(\"../data/replay_buffer/run-7-cnn.npy\", batch_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from jax import numpy as jnp\n",
    "from network.transformer import create_concat_input\n",
    "from batch import get_tokens, get_posses, get_color\n",
    "\n",
    "\n",
    "def pos_to_board(\n",
    "    pos1: jnp.ndarray,\n",
    "    pos2: jnp.ndarray,\n",
    "    color1: jnp.ndarray,\n",
    "    color2: jnp.ndarray\n",
    ") -> jnp.ndarray:\n",
    "    batch_shape = pos1.shape[:-1]\n",
    "\n",
    "    pos1 = pos1.reshape(-1, 8)\n",
    "    pos2 = pos2.reshape(-1, 8)\n",
    "    color1 = color1.reshape(-1, 8)\n",
    "    color2 = color2.reshape(-1, 8)\n",
    "\n",
    "    def scan_f(x_i) -> jnp.ndarray:\n",
    "        p1, p2, c1, c2 = [x_i[i*8: (i+1)*8] for i in range(4)]\n",
    "\n",
    "        board = jnp.zeros((37, 4), dtype=jnp.uint8)\n",
    "        board = board.at[p1, 0].set(c1)\n",
    "        board = board.at[p1, 1].set(255 - c1)\n",
    "        board = board.at[p2, 2].set(c2)\n",
    "        board = board.at[p2, 3].set(255 - c2)\n",
    "\n",
    "        return None, board\n",
    "\n",
    "    xs = jnp.concatenate([pos1, pos2, color1, color2], axis=-1, dtype=jnp.uint8)\n",
    "\n",
    "    _, board = jnp.apply_along_axis(scan_f, axis=-1, arr=xs)\n",
    "\n",
    "    board = board[..., :36, :].reshape((*batch_shape, 6, 6, 4))\n",
    "\n",
    "    return board\n",
    "\n",
    "j = 3\n",
    "\n",
    "x = get_tokens(batch_org[j: j+10])\n",
    "pos = get_posses(batch_org[j: j+10])\n",
    "col = get_color(batch_org[j: j+10])\n",
    "concat = create_concat_input(x, pos, col)\n",
    "\n",
    "color_1 = jnp.stack([x[..., :8, 0]]*x.shape[-2], axis=-2) * 200 + 20\n",
    "color_2 = jnp.stack([col]*x.shape[-2], axis=-2) * 200 + 20\n",
    "board = pos_to_board(pos[..., :8], pos[..., 8:], color_1, color_2)\n",
    "# board = board.astype(jnp.float16) / 255.0\n",
    "\n",
    "for j in range(10):\n",
    "    for i in range(20, 21):\n",
    "        print(i, x[j, i, :], concat[j, i])\n",
    "        print()\n",
    "        print(pos[j, i, :8], pos[j, i, 8:])\n",
    "        print(color_1[j, i], color_2[j, i])\n",
    "        print()\n",
    "        print(board[j, i, :, :, 0])\n",
    "        print()\n",
    "        print(board[j, i, :, :, 1])\n",
    "        print()\n",
    "        print(board[j, i, :, :, 2])\n",
    "        print()\n",
    "        print(board[j, i, :, :, 3])\n",
    "        print()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from batch import load, astuple, get_reward\n",
    "\n",
    "batch_org = load(\"../data/replay_buffer/run-7-cnn.npy\")\n",
    "\n",
    "batch_org = batch_org.reshape(-1, batch_org.shape[-1])\n",
    "\n",
    "indices = np.arange(len(batch_org))\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "batch_org = batch_org[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1268736, 4849)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 10:03:09.732463: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "100%|██████████| 9921/9921 [02:52<00:00, 57.60it/s, loss=6.289] \n",
      "100%|██████████| 2480/2480 [00:19<00:00, 127.41it/s, loss=6.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: (7.735, 6.744), P1: (1.722, 1.351), P2: (2.074, 1.648), V1: (1.630, 1.577), V2: (1.633, 1.605), C: (0.675, 0.563)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:35<00:00, 63.81it/s, loss=5.978]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 150.10it/s, loss=6.596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: (6.622, 6.414), P1: (1.335, 1.216), P2: (1.581, 1.533), V1: (1.570, 1.559), V2: (1.594, 1.589), C: (0.541, 0.517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:37<00:00, 63.15it/s, loss=5.855]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 148.38it/s, loss=6.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: (6.393, 6.277), P1: (1.234, 1.151), P2: (1.509, 1.492), V1: (1.552, 1.546), V2: (1.580, 1.581), C: (0.518, 0.507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:35<00:00, 63.78it/s, loss=5.743]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 151.30it/s, loss=6.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: (6.273, 6.176), P1: (1.177, 1.103), P2: (1.475, 1.466), V1: (1.541, 1.536), V2: (1.573, 1.575), C: (0.507, 0.496)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:36<00:00, 63.55it/s, loss=5.634]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 150.13it/s, loss=6.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: (6.193, 6.115), P1: (1.138, 1.074), P2: (1.453, 1.448), V1: (1.533, 1.529), V2: (1.567, 1.572), C: (0.501, 0.493)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:36<00:00, 63.46it/s, loss=5.643]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 149.16it/s, loss=6.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: (6.137, 6.067), P1: (1.113, 1.051), P2: (1.437, 1.434), V1: (1.527, 1.524), V2: (1.563, 1.568), C: (0.498, 0.490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:35<00:00, 63.69it/s, loss=5.607]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 151.18it/s, loss=6.187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: (6.095, 6.038), P1: (1.095, 1.040), P2: (1.424, 1.423), V1: (1.523, 1.523), V2: (1.560, 1.565), C: (0.494, 0.487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9921/9921 [02:34<00:00, 64.11it/s, loss=5.570]\n",
      "100%|██████████| 2480/2480 [00:16<00:00, 154.08it/s, loss=6.184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: (6.061, 6.011), P1: (1.080, 1.030), P2: (1.414, 1.414), V1: (1.519, 1.520), V2: (1.557, 1.562), C: (0.491, 0.485)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 1, Loss: (4.711, 4.095), P: (2.292, 1.753), V: (1.720, 1.660), C: (0.699, 0.683)\\nEpoch: 2, Loss: (3.987, 3.741), P: (1.717, 1.567), V: (1.639, 1.617), C: (0.631, 0.557)\\nEpoch: 3, Loss: (3.738, 3.603), P: (1.583, 1.479), V: (1.609, 1.601), C: (0.546, 0.524)\\nEpoch: 4, Loss: (3.619, 3.527), P: (1.510, 1.426), V: (1.589, 1.588), C: (0.520, 0.513)\\nEpoch: 5, Loss: (3.547, 3.460), P: (1.463, 1.390), V: (1.576, 1.575), C: (0.508, 0.495)\\nEpoch: 6, Loss: (3.491, 3.429), P: (1.428, 1.367), V: (1.563, 1.568), C: (0.500, 0.494)\\nEpoch: 7, Loss: (3.450, 3.396), P: (1.401, 1.344), V: (1.554, 1.563), C: (0.494, 0.488)\\nEpoch: 8, Loss: (3.416, 3.371), P: (1.380, 1.328), V: (1.546, 1.558), C: (0.491, 0.485)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "import optax\n",
    "from network.cnn import CNNConfig\n",
    "from network.transformer import TransformerConfig, TrainStateTransformer, create_concat_input\n",
    "from network.train import fit, MinibatchProducerSimple\n",
    "from network.checkpoints import Checkpoint, CheckpointManager\n",
    "from batch import get_tokens, get_posses, get_color, get_reward\n",
    "\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "batch = batch_org[:200000]\n",
    "\n",
    "r = get_reward(batch)\n",
    "batch = batch[get_reward(batch) != 3]\n",
    "\n",
    "n_train = int(batch.shape[0] * 0.8)\n",
    "train_batch = batch[:n_train]\n",
    "test_batch = batch[n_train:]\n",
    "\n",
    "minibatch_producer = MinibatchProducerSimple(batch_size=16)\n",
    "\n",
    "heads = 4,\n",
    "dims = 256,\n",
    "num_layers = 4,\n",
    "\n",
    "for h, d, n in itertools.product(heads, dims, num_layers):\n",
    "    model_config = TransformerConfig(\n",
    "        num_heads=h,\n",
    "        embed_dim=d,\n",
    "        num_hidden_layers=n,\n",
    "        cnn_config=CNNConfig(num_filters=[64, 64]),\n",
    "    )\n",
    "    model = model_config.create_model()\n",
    "\n",
    "    init_x = get_tokens(train_batch[:1])\n",
    "    init_pos = get_posses(train_batch[:1])\n",
    "    init_color = get_color(train_batch[:1])\n",
    "    init_concat = create_concat_input(init_x, init_pos, init_color)\n",
    "\n",
    "    # variables = model.init(random.PRNGKey(0), init_x)\n",
    "    variables = model.init(random.PRNGKey(0), init_x, pos=init_pos, concat=init_concat)\n",
    "    state = TrainStateTransformer.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=variables['params'],\n",
    "        tx=optax.adam(learning_rate=0.0005),\n",
    "        dropout_rng=random.PRNGKey(0),\n",
    "        epoch=0,\n",
    "    )\n",
    "\n",
    "    ckpt_dir = f'./data/checkpoints/tr'\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(ckpt_dir)\n",
    "    checkpoint_manager.save(Checkpoint(state.epoch, model_config, state.params))\n",
    "\n",
    "    state = fit(\n",
    "        state, model_config, checkpoint_manager,\n",
    "        train_batches=train_batch,\n",
    "        test_batches=test_batch,\n",
    "        minibatch_producer=minibatch_producer,\n",
    "        epochs=8,\n",
    "        log_wandb=False\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "Epoch: 1, Loss: (4.711, 4.095), P: (2.292, 1.753), V: (1.720, 1.660), C: (0.699, 0.683)\n",
    "Epoch: 2, Loss: (3.987, 3.741), P: (1.717, 1.567), V: (1.639, 1.617), C: (0.631, 0.557)\n",
    "Epoch: 3, Loss: (3.738, 3.603), P: (1.583, 1.479), V: (1.609, 1.601), C: (0.546, 0.524)\n",
    "Epoch: 4, Loss: (3.619, 3.527), P: (1.510, 1.426), V: (1.589, 1.588), C: (0.520, 0.513)\n",
    "Epoch: 5, Loss: (3.547, 3.460), P: (1.463, 1.390), V: (1.576, 1.575), C: (0.508, 0.495)\n",
    "Epoch: 6, Loss: (3.491, 3.429), P: (1.428, 1.367), V: (1.563, 1.568), C: (0.500, 0.494)\n",
    "Epoch: 7, Loss: (3.450, 3.396), P: (1.401, 1.344), V: (1.554, 1.563), C: (0.494, 0.488)\n",
    "Epoch: 8, Loss: (3.416, 3.371), P: (1.380, 1.328), V: (1.546, 1.558), C: (0.491, 0.485)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003086102854111314\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import optax\n",
    "from jax import random, numpy as jnp\n",
    "from network.checkpoints import Checkpoint, CheckpointManager\n",
    "from network.transformer import TransformerWithCache, TrainStateTransformer\n",
    "from batch import get_tokens, get_posses, get_color\n",
    "\n",
    "ckpt = Checkpoint.from_json_file(\"data/checkpoints/tr/4.json\")\n",
    "\n",
    "model = ckpt.model.create_caching_model()\n",
    "\n",
    "tokens = get_tokens(train_batch[:10])\n",
    "\n",
    "cache = model.create_cache(seq_len=200)\n",
    "\n",
    "state = TrainStateTransformer.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=ckpt.params,\n",
    "        tx=optax.adam(learning_rate=0.0005),\n",
    "        dropout_rng=random.PRNGKey(0),\n",
    "        epoch=0,\n",
    "    )\n",
    "\n",
    "@partial(jax.jit, device=jax.devices(\"cpu\")[0])\n",
    "def apply(state: TrainStateTransformer, x, cache):\n",
    "    return state.apply_fn({\"params\": state.params}, x, cache=cache)\n",
    "\n",
    "apply(state, tokens[0, 0], cache=cache)\n",
    "\n",
    "count = 0\n",
    "start_t = time.perf_counter()\n",
    "\n",
    "for i in range(10):\n",
    "    cache = model.create_cache(seq_len=200)\n",
    "\n",
    "    for j in range(200):\n",
    "        if jnp.all(tokens[i, j] == 0):\n",
    "            break\n",
    "\n",
    "        _, p, v, c, cache = apply(state, tokens[i, j], cache=cache)\n",
    "        count += 1\n",
    "\n",
    "print((time.perf_counter() - start_t) / count)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003845642949602189\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import optax\n",
    "from jax import random, numpy as jnp\n",
    "from network.checkpoints import Checkpoint, CheckpointManager\n",
    "from network.transformer import create_concat_input\n",
    "from network.cnn import CNN, TrainStateCNN, pos_to_board\n",
    "from batch import get_tokens, get_posses, get_color\n",
    "\n",
    "ckpt = Checkpoint.from_json_file(\"data/checkpoints/tr/1.json\")\n",
    "\n",
    "model = ckpt.model.cnn_config.create_model()\n",
    "\n",
    "tokens = get_tokens(train_batch[:10])\n",
    "pos = get_posses(train_batch[:10])\n",
    "col = get_color(train_batch[:10])\n",
    "\n",
    "concat = create_concat_input(tokens, pos, col)\n",
    "\n",
    "col1 = tokens[..., :8, 0]\n",
    "col1 = jnp.stack([col1]*tokens.shape[-2], axis=-2) * 255\n",
    "col2 = np.random.randint(0, 255, size=col1.shape)\n",
    "\n",
    "board = pos_to_board(pos[..., :8], pos[..., 8:], col1, col2)\n",
    "\n",
    "state = TrainStateCNN.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=ckpt.params[\"cnn\"],\n",
    "        tx=optax.adam(learning_rate=0.0005),\n",
    "        dropout_rng=random.PRNGKey(0),\n",
    "        epoch=0,\n",
    "    )\n",
    "\n",
    "@partial(jax.jit, device=jax.devices(\"cpu\")[0])\n",
    "def apply(state: TrainStateTransformer, x, concat):\n",
    "    return state.apply_fn({\"params\": state.params}, x, concat=concat)\n",
    "\n",
    "apply(state, board[:1, :1], concat[:1, :1])\n",
    "\n",
    "count = 0\n",
    "start_t = time.perf_counter()\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(200):\n",
    "        if jnp.all(tokens[i, j] == 0):\n",
    "            break\n",
    "\n",
    "        p, v = apply(state, board[i:i+1, j:j+1], concat[i:i+1, j:j+1])\n",
    "        count += 1\n",
    "\n",
    "print((time.perf_counter() - start_t) / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.081, 0.027, 0.067, 0.004, 0.745, 0.042, 0.034\n",
      "|   \u001b[31mR\u001b[0m  \u001b[31mR\u001b[0m  \u001b[31mR\u001b[0m      |\n",
      "|   \u001b[34mB\u001b[0m  \u001b[34mB\u001b[0m  \u001b[34mB\u001b[0m      |\n",
      "|                |\n",
      "|      \u001b[31mR\u001b[0m  5      |\n",
      "|      5         |\n",
      "|   5  5  5     \u001b[34mB\u001b[0m|\n",
      "blue=0 red=0\n"
     ]
    }
   ],
   "source": [
    "import flax.linen\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "import flax\n",
    "from network.cnn import pos_to_board\n",
    "from network.transformer import TransformerConfig, TrainStateTransformer, create_concat_input\n",
    "from network.train import fit, MinibatchProducerSimple\n",
    "from network.checkpoints import Checkpoint, CheckpointManager\n",
    "from batch import get_tokens, get_posses, get_color\n",
    "\n",
    "from env.state import State\n",
    "from game_analytics import state_to_str\n",
    "\n",
    "ckpt = Checkpoint.from_json_file(\"data/checkpoints/tr/4.json\")\n",
    "\n",
    "model = ckpt.model.cnn_config.create_model()\n",
    "\n",
    "pos1 = jnp.array([[1, 2, 3, 20, 7, 8, 9, 35]], dtype=jnp.uint8)\n",
    "col1 = jnp.array([[0, 0, 0, 0, 1, 1, 1, 1]], dtype=jnp.uint8) * 255\n",
    "\n",
    "pos2 = jnp.array([[21, 33, 32, 31, 26, 36, 36, 36]], dtype=jnp.uint8)\n",
    "col2 = jnp.array([[255, 128, 128, 128, 128, 128, 128, 128]], dtype=jnp.uint8)\n",
    "\n",
    "concat = jnp.array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=jnp.uint8)\n",
    "\n",
    "n_cap_r = 3\n",
    "n_cap_b = 0\n",
    "\n",
    "concat = concat.at[n_cap_r].set(1)\n",
    "concat = concat.at[4 + n_cap_b].set(1)\n",
    "\n",
    "board = pos_to_board(pos1, pos2, col1, col2)\n",
    "\n",
    "p, v = model.apply({\"params\": ckpt.params[\"cnn\"]}, board, concat=concat)\n",
    "\n",
    "print(\", \".join([f\"{f:.3f}\" for f in flax.linen.softmax(v[0])]))\n",
    "\n",
    "# 0.221, 0.082, 0.315, 0.015, 0.231, 0.062, 0.074\n",
    "# 0.333, 0.098, 0.185, 0.011, 0.208, 0.060, 0.105\n",
    "\n",
    "print(state_to_str(State(jnp.array([pos1[0], pos2[0], col1[0] // 255, jnp.array([3]*8)]), n_ply=10), predicted_color=[0.5]*8, colored=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geister12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
